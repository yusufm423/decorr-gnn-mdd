{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXhZl5V666Fw"
      },
      "source": [
        "## Gradcam calculation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grad-CAM was originally developed for CNNs in the computer-vision domain [[1]](http://cnnlocalization.csail.mit.edu/Zhou_Learning_Deep_Features_CVPR_2016_paper.pdf)\n",
        ". Its recent adaptation to GCNs allows the identification of discriminative nodes in non-Euclidean graph structures beyond image space [[2]](https://link.springer.com/book/10.1007/978-3-030-00689-1). In this work, we follow the Grad-CAM strategy described in [[3]](https://www.sciencedirect.com/science/article/pii/S016503272300928X) to highlight brain regions that uniquely contribute to classification outcomes across male and female groups.\n",
        "\n",
        "\n",
        "> Steps\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Here, we compute Grad-CAM values at the input level of the GCN using a (Gradient √ó Input) strategy. First, the input feature matrix\n",
        "ùëâ is set to require gradients, and the model performs a forward pass to generate class scores. The softmax probability corresponding to the MDD class is then selected, and gradients of this target score with respect to the input ùëâ are obtained via backpropagation. These gradients capture how sensitive the prediction is to changes in each input element. To quantify contribution, the gradients are multiplied element-wise with the original input features, producing a Grad-CAM map that highlights the most influential input positions. Finally, the Grad-CAM values are averaged across the feature dimension to yield a contribution score for each ROI, indicating its importance in predicting the MDD class. This procedure is applied separately for models trained on male and female subjects to identify sex-specific discriminative brain regions.\n"
      ],
      "metadata": {
        "id": "I9B8DPw-D01C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekdOxyjm66Fx"
      },
      "outputs": [],
      "source": [
        "def calculate_grad_cam(model, data):\n",
        "    data = data.to(device)\n",
        "    model.zero_grad()\n",
        "    data.x.requires_grad = True\n",
        "\n",
        "    output, _ = model(data)\n",
        "\n",
        "    scores = F.softmax(output, dim=1)\n",
        "    print(scores.shape)\n",
        "    print(scores[0])\n",
        "\n",
        "    scores_mdd = scores[:, 1]\n",
        "    print('scores = ',scores_mdd.shape)\n",
        "\n",
        "    scores_mdd.backward(torch.ones_like(scores_mdd))\n",
        "\n",
        "    gradients = data.x.grad\n",
        "    print('gradients = ',gradients.shape)\n",
        "\n",
        "    # Calculate Grad-CAM values\n",
        "    grad_cam = gradients * data.x\n",
        "    print('data.x = ',data.x.shape)\n",
        "    print('gradcam = ',grad_cam.shape)\n",
        "\n",
        "    contribution = torch.mean(grad_cam, dim=1)\n",
        "\n",
        "    print('contribution = ',contribution.shape)\n",
        "\n",
        "    return scores, grad_cam, contribution"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}